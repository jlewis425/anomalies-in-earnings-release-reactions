{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quandl experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quandl\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quandl authentication\n",
    "\n",
    "quandl.ApiConfig.api_key = \"jUKZLy5xi7gGFf3sSF-r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hv10</th>\n",
       "      <th>Hv20</th>\n",
       "      <th>Hv30</th>\n",
       "      <th>Hv60</th>\n",
       "      <th>Hv90</th>\n",
       "      <th>Hv120</th>\n",
       "      <th>Hv150</th>\n",
       "      <th>Hv180</th>\n",
       "      <th>Phv10</th>\n",
       "      <th>Phv20</th>\n",
       "      <th>...</th>\n",
       "      <th>IvMean360</th>\n",
       "      <th>IvMeanSkew360</th>\n",
       "      <th>IvCall720</th>\n",
       "      <th>IvPut720</th>\n",
       "      <th>IvMean720</th>\n",
       "      <th>IvMeanSkew720</th>\n",
       "      <th>IvCall1080</th>\n",
       "      <th>IvPut1080</th>\n",
       "      <th>IvMean1080</th>\n",
       "      <th>IvMeanSkew1080</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-29</th>\n",
       "      <td>0.2451</td>\n",
       "      <td>0.1834</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.2927</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.1649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.2334</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.2334</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Hv10    Hv20    Hv30    Hv60    Hv90   Hv120   Hv150   Hv180  \\\n",
       "Date                                                                         \n",
       "2019-03-29  0.2451  0.1834  0.1733  0.1804  0.2281  0.2927  0.2983  0.3202   \n",
       "\n",
       "             Phv10   Phv20  ...  IvMean360  IvMeanSkew360  IvCall720  \\\n",
       "Date                        ...                                        \n",
       "2019-03-29  0.1879  0.1649  ...     0.2212         0.0217     0.2021   \n",
       "\n",
       "            IvPut720  IvMean720  IvMeanSkew720  IvCall1080  IvPut1080  \\\n",
       "Date                                                                    \n",
       "2019-03-29    0.2647     0.2334         0.0039      0.2021     0.2647   \n",
       "\n",
       "            IvMean1080  IvMeanSkew1080  \n",
       "Date                                    \n",
       "2019-03-29      0.2334          0.0039  \n",
       "\n",
       "[1 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore Quantcha US Equity Historical & Option Implied Volatilities\n",
    "\n",
    "vols_sample = quandl.get('VOL/MSFT', start_date='2019-03-29', end_date='2019-03-29')\n",
    "vols_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of column names\n",
    "\n",
    "col_names = list(vols_sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of column numbers corresponding to column headings\n",
    "\n",
    "col_name_index = {name:idx+1 for idx, name in enumerate(col_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hv10': 1,\n",
       " 'Hv20': 2,\n",
       " 'Hv30': 3,\n",
       " 'Hv60': 4,\n",
       " 'Hv90': 5,\n",
       " 'Hv120': 6,\n",
       " 'Hv150': 7,\n",
       " 'Hv180': 8,\n",
       " 'Phv10': 9,\n",
       " 'Phv20': 10,\n",
       " 'Phv30': 11,\n",
       " 'Phv60': 12,\n",
       " 'Phv90': 13,\n",
       " 'Phv120': 14,\n",
       " 'Phv150': 15,\n",
       " 'Phv180': 16,\n",
       " 'IvCall10': 17,\n",
       " 'IvPut10': 18,\n",
       " 'IvMean10': 19,\n",
       " 'IvMeanSkew10': 20,\n",
       " 'IvCall20': 21,\n",
       " 'IvPut20': 22,\n",
       " 'IvMean20': 23,\n",
       " 'IvMeanSkew20': 24,\n",
       " 'IvCall30': 25,\n",
       " 'IvPut30': 26,\n",
       " 'IvMean30': 27,\n",
       " 'IvMeanSkew30': 28,\n",
       " 'IvCall60': 29,\n",
       " 'IvPut60': 30,\n",
       " 'IvMean60': 31,\n",
       " 'IvMeanSkew60': 32,\n",
       " 'IvCall90': 33,\n",
       " 'IvPut90': 34,\n",
       " 'IvMean90': 35,\n",
       " 'IvMeanSkew90': 36,\n",
       " 'IvCall120': 37,\n",
       " 'IvPut120': 38,\n",
       " 'IvMean120': 39,\n",
       " 'IvMeanSkew120': 40,\n",
       " 'IvCall150': 41,\n",
       " 'IvPut150': 42,\n",
       " 'IvMean150': 43,\n",
       " 'IvMeanSkew150': 44,\n",
       " 'IvCall180': 45,\n",
       " 'IvPut180': 46,\n",
       " 'IvMean180': 47,\n",
       " 'IvMeanSkew180': 48,\n",
       " 'IvCall270': 49,\n",
       " 'IvPut270': 50,\n",
       " 'IvMean270': 51,\n",
       " 'IvMeanSkew270': 52,\n",
       " 'IvCall360': 53,\n",
       " 'IvPut360': 54,\n",
       " 'IvMean360': 55,\n",
       " 'IvMeanSkew360': 56,\n",
       " 'IvCall720': 57,\n",
       " 'IvPut720': 58,\n",
       " 'IvMean720': 59,\n",
       " 'IvMeanSkew720': 60,\n",
       " 'IvCall1080': 61,\n",
       " 'IvPut1080': 62,\n",
       " 'IvMean1080': 63,\n",
       " 'IvMeanSkew1080': 64}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json of column name:index pairs for Quantcha Volatility data\n",
    "\n",
    "#with open('vol_col_names.json', 'w') as fp:\n",
    "#    json.dump(col_name_index, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hv90</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-29</th>\n",
       "      <td>0.3189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-02</th>\n",
       "      <td>0.3252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-03</th>\n",
       "      <td>0.3261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-04</th>\n",
       "      <td>0.3309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>0.3305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-06</th>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>0.3335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-10</th>\n",
       "      <td>0.3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-11</th>\n",
       "      <td>0.3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12</th>\n",
       "      <td>0.3391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-13</th>\n",
       "      <td>0.3378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>0.3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>0.3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-18</th>\n",
       "      <td>0.3371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-19</th>\n",
       "      <td>0.3372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20</th>\n",
       "      <td>0.3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-23</th>\n",
       "      <td>0.3364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>0.3403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>0.3409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>0.3424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>0.3451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>0.3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-02</th>\n",
       "      <td>0.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03</th>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-04</th>\n",
       "      <td>0.3293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-07</th>\n",
       "      <td>0.3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>0.3193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>0.3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>0.2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-15</th>\n",
       "      <td>0.3434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-19</th>\n",
       "      <td>0.3406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>0.3403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>0.3354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>0.3311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>0.3303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>0.3305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-27</th>\n",
       "      <td>0.3244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>0.3242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>0.3160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>0.3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>0.3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06</th>\n",
       "      <td>0.3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07</th>\n",
       "      <td>0.3087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08</th>\n",
       "      <td>0.3085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-11</th>\n",
       "      <td>0.2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-12</th>\n",
       "      <td>0.2954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-13</th>\n",
       "      <td>0.2952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-14</th>\n",
       "      <td>0.2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-15</th>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-18</th>\n",
       "      <td>0.2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-19</th>\n",
       "      <td>0.2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-20</th>\n",
       "      <td>0.2814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-21</th>\n",
       "      <td>0.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-22</th>\n",
       "      <td>0.2864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-25</th>\n",
       "      <td>0.2772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>0.2610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>0.2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28</th>\n",
       "      <td>0.2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29</th>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Hv90\n",
       "Date              \n",
       "2018-03-29  0.3189\n",
       "2018-04-02  0.3252\n",
       "2018-04-03  0.3261\n",
       "2018-04-04  0.3309\n",
       "2018-04-05  0.3305\n",
       "2018-04-06  0.3333\n",
       "2018-04-09  0.3335\n",
       "2018-04-10  0.3366\n",
       "2018-04-11  0.3373\n",
       "2018-04-12  0.3391\n",
       "2018-04-13  0.3378\n",
       "2018-04-16  0.3371\n",
       "2018-04-17  0.3371\n",
       "2018-04-18  0.3371\n",
       "2018-04-19  0.3372\n",
       "2018-04-20  0.3364\n",
       "2018-04-23  0.3364\n",
       "2018-04-24  0.3400\n",
       "2018-04-25  0.3403\n",
       "2018-04-26  0.3409\n",
       "2018-04-27  0.3424\n",
       "2018-04-30  0.3451\n",
       "2018-05-01  0.3430\n",
       "2018-05-02  0.3442\n",
       "2018-05-03  0.3400\n",
       "2018-05-04  0.3293\n",
       "2018-05-07  0.3217\n",
       "2018-05-08  0.3193\n",
       "2018-05-09  0.3003\n",
       "2018-05-10  0.2923\n",
       "...            ...\n",
       "2019-02-15  0.3434\n",
       "2019-02-19  0.3406\n",
       "2019-02-20  0.3403\n",
       "2019-02-21  0.3354\n",
       "2019-02-22  0.3311\n",
       "2019-02-25  0.3303\n",
       "2019-02-26  0.3305\n",
       "2019-02-27  0.3244\n",
       "2019-02-28  0.3242\n",
       "2019-03-01  0.3160\n",
       "2019-03-04  0.3155\n",
       "2019-03-05  0.3155\n",
       "2019-03-06  0.3147\n",
       "2019-03-07  0.3087\n",
       "2019-03-08  0.3085\n",
       "2019-03-11  0.2994\n",
       "2019-03-12  0.2954\n",
       "2019-03-13  0.2952\n",
       "2019-03-14  0.2951\n",
       "2019-03-15  0.2958\n",
       "2019-03-18  0.2893\n",
       "2019-03-19  0.2818\n",
       "2019-03-20  0.2814\n",
       "2019-03-21  0.2843\n",
       "2019-03-22  0.2864\n",
       "2019-03-25  0.2772\n",
       "2019-03-26  0.2610\n",
       "2019-03-27  0.2289\n",
       "2019-03-28  0.2288\n",
       "2019-03-29  0.2281\n",
       "\n",
       "[252 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get one year of 90 day realized vols\n",
    "\n",
    "quandl.get('VOL/MSFT', start_date='2018-03-29', end_date='2019-03-29', column_index='5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionary of column_name:column_index pairs for Quantcha Volatility data\n",
    "\n",
    "with open('data/vol_col_names.json') as json_data:\n",
    "    vol_col_names = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function for relative date comparisons\n",
    "\n",
    "def vol_delta(ticker, date, look_back_days):\n",
    "    \"\"\"Provides the 90D stock volatility for the date relative to the date implied by the look back days\n",
    "    argument. For consistent results, utilize a look_back_days window that is a multiple of 7.\n",
    "    Output is based on the formula: <current volatility> / <previous volatility>\n",
    "    Package dependencies: datetime, timedelta\n",
    "    \"\"\"\n",
    "    \n",
    "    date = datetime.strptime(date, '%Y-%m-%d')\n",
    "    \n",
    "    lookback_date = date - timedelta(days=int(look_back_days))\n",
    "        \n",
    "    date = str(date)\n",
    "    date = date[0:10]\n",
    "    \n",
    "    lookback_date = str(lookback_date)\n",
    "    lookback_date = lookback_date[0:10]\n",
    "    \n",
    "      \n",
    "    curr_vol = quandl.get('VOL/'+ticker, start_date=date, end_date=date, column_index='5')\n",
    "    \n",
    "    prior_vol = quandl.get('VOL/'+ticker, start_date=lookback_date, end_date=lookback_date, column_index='5')\n",
    "    \n",
    "    \n",
    "    \n",
    "    output = curr_vol.values / prior_vol.values\n",
    "    return float(output)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a generalized measure delta function\n",
    "\n",
    "def measure_delta(ticker, date, look_back_days, measure='Hv90'):\n",
    "    \"\"\"Provides a relative comparison for a given stock ticker and date, based on an arbitrary look_back_window,\n",
    "    for any of 64 data itmes from the Quantcha Historical and Implied Volatility API.\n",
    "    \n",
    "    INPUTS: 'Ticker', 'YYYY-MM-DD', lookback days (as integer), and measure name.\n",
    "    For reference, measure names are contained in the dictionary: vol_col_names\n",
    "    ***NOTE: For best results, utilize a lookback window that is a multiple of 7 days from the given date.\n",
    "    \n",
    "    OUPUT: A float, based on the forumla: <measure at date> / <measure at date - lookback days>\n",
    "    \"\"\"\n",
    "    \n",
    "    date = datetime.strptime(date, '%Y-%m-%d')\n",
    "    \n",
    "    lookback_date = date - timedelta(days=int(look_back_days))\n",
    "        \n",
    "    date = str(date)\n",
    "    date = date[0:10]\n",
    "    \n",
    "    lookback_date = str(lookback_date)\n",
    "    lookback_date = lookback_date[0:10]\n",
    "    \n",
    "      \n",
    "    curr_vol = (quandl.get('VOL/'+ticker,\n",
    "                           start_date=date,\n",
    "                           end_date=date, \n",
    "                           column_index=vol_col_names.get(measure)))\n",
    "                \n",
    "    \n",
    "    prior_vol = (quandl.get('VOL/'+ticker,\n",
    "                            start_date=lookback_date,\n",
    "                            end_date=lookback_date,\n",
    "                            column_index=vol_col_names.get(measure)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    output = curr_vol.values / prior_vol.values\n",
    "    return float(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a helper function for getting a measure from the quantcha / quandl API\n",
    "\n",
    "def get_vol_measure(ticker, date, measure='Hv90'):\n",
    "    \"\"\"Retrieves a value from the Quantcha Historical and Implied Volatility API for a given stock and date.\n",
    "    \n",
    "    INPUTS: 'Ticker', 'YYYY-MM-DD', and measure name.\n",
    "    For reference, measure names are contained in the dictionary: vol_col_names\n",
    "        \n",
    "    OUPUT: A float\n",
    "    \"\"\"\n",
    "    \n",
    "    measure_value = (quandl.get('VOL/'+ticker,\n",
    "                           start_date=date,\n",
    "                           end_date=date, \n",
    "                           column_index=vol_col_names.get(measure)))\n",
    "                \n",
    "    \n",
    "    return float(measure_value.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample function for doing vol comparisons\n",
    "\n",
    "def vol_delta_90d(ticker, old_date, new_date):\n",
    "    \"\"\"Provides the 90D stock volatility for the new date relative to the prior date as a float,\n",
    "    based on the formula <current volatility> / <previous volatility>\"\"\"\n",
    "    prior_vol = quandl.get('VOL/'+ticker, start_date=old_date, end_date=old_date, column_index='5')\n",
    "    curr_vol = quandl.get('VOL/'+ticker, start_date=new_date, end_date=new_date, column_index='5')\n",
    "    output = curr_vol.values / prior_vol.values\n",
    "    return float(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1743119266055055"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_delta('SLB', \"2019-03-29\", 84, measure='IvMeanSkew30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hv10': 1,\n",
       " 'Hv20': 2,\n",
       " 'Hv30': 3,\n",
       " 'Hv60': 4,\n",
       " 'Hv90': 5,\n",
       " 'Hv120': 6,\n",
       " 'Hv150': 7,\n",
       " 'Hv180': 8,\n",
       " 'Phv10': 9,\n",
       " 'Phv20': 10,\n",
       " 'Phv30': 11,\n",
       " 'Phv60': 12,\n",
       " 'Phv90': 13,\n",
       " 'Phv120': 14,\n",
       " 'Phv150': 15,\n",
       " 'Phv180': 16,\n",
       " 'IvCall10': 17,\n",
       " 'IvPut10': 18,\n",
       " 'IvMean10': 19,\n",
       " 'IvMeanSkew10': 20,\n",
       " 'IvCall20': 21,\n",
       " 'IvPut20': 22,\n",
       " 'IvMean20': 23,\n",
       " 'IvMeanSkew20': 24,\n",
       " 'IvCall30': 25,\n",
       " 'IvPut30': 26,\n",
       " 'IvMean30': 27,\n",
       " 'IvMeanSkew30': 28,\n",
       " 'IvCall60': 29,\n",
       " 'IvPut60': 30,\n",
       " 'IvMean60': 31,\n",
       " 'IvMeanSkew60': 32,\n",
       " 'IvCall90': 33,\n",
       " 'IvPut90': 34,\n",
       " 'IvMean90': 35,\n",
       " 'IvMeanSkew90': 36,\n",
       " 'IvCall120': 37,\n",
       " 'IvPut120': 38,\n",
       " 'IvMean120': 39,\n",
       " 'IvMeanSkew120': 40,\n",
       " 'IvCall150': 41,\n",
       " 'IvPut150': 42,\n",
       " 'IvMean150': 43,\n",
       " 'IvMeanSkew150': 44,\n",
       " 'IvCall180': 45,\n",
       " 'IvPut180': 46,\n",
       " 'IvMean180': 47,\n",
       " 'IvMeanSkew180': 48,\n",
       " 'IvCall270': 49,\n",
       " 'IvPut270': 50,\n",
       " 'IvMean270': 51,\n",
       " 'IvMeanSkew270': 52,\n",
       " 'IvCall360': 53,\n",
       " 'IvPut360': 54,\n",
       " 'IvMean360': 55,\n",
       " 'IvMeanSkew360': 56,\n",
       " 'IvCall720': 57,\n",
       " 'IvPut720': 58,\n",
       " 'IvMean720': 59,\n",
       " 'IvMeanSkew720': 60,\n",
       " 'IvCall1080': 61,\n",
       " 'IvPut1080': 62,\n",
       " 'IvMean1080': 63,\n",
       " 'IvMeanSkew1080': 64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.304"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vol_measure('NFLX', '2019-03-29', measure='Hv30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8307667369103582"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_delta_90d(\"TSLA\", \"2019-01-02\", \"2019-03-29\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = quandl.get('VOL/MSFT', start_date='2018-03-29', end_date='2019-03-29', column_index='5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 252 entries, 2018-03-29 to 2019-03-29\n",
      "Data columns (total 1 columns):\n",
      "Hv90    252 non-null float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.9 KB\n"
     ]
    }
   ],
   "source": [
    "example.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of 'surprise' files\n",
    "\n",
    "surp_files = (['surp_1q14.csv',\n",
    "               'surp_2q14.csv',\n",
    "               'surp_3q14.csv',\n",
    "               'surp_4q14.csv',\n",
    "               'surp_1q15.csv',\n",
    "               'surp_2q15.csv',\n",
    "               'surp_3q15.csv',\n",
    "               'surp_4q15.csv',\n",
    "               'surp_1q16.csv',\n",
    "               'surp_2q16.csv',\n",
    "               'surp_3q16.csv',\n",
    "               'surp_4q16.csv',\n",
    "               'surp_1q17.csv',\n",
    "               'surp_2q17.csv',\n",
    "               'surp_3q17.csv',\n",
    "               'surp_4q17.csv',\n",
    "               'surp_1q18.csv',\n",
    "               'surp_2q18.csv',\n",
    "               'surp_3q18.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of 'features' files\n",
    "\n",
    "features_files = (['features_1q14.csv',\n",
    "                   'features_2q14.csv',\n",
    "                   'features_3q14.csv',\n",
    "                   'features_4q14.csv',\n",
    "                   'features_1q15.csv',\n",
    "                   'features_2q15.csv',\n",
    "                   'features_3q15.csv',\n",
    "                   'features_4q15.csv',\n",
    "                   'features_1q16.csv',\n",
    "                   'features_2q16.csv',\n",
    "                   'features_3q16.csv',\n",
    "                   'features_4q16.csv',\n",
    "                   'features_1q17.csv',\n",
    "                   'features_2q17.csv',\n",
    "                   'features_3q17.csv',\n",
    "                   'features_4q17.csv',\n",
    "                   'features_1q18.csv',\n",
    "                   'features_2q18.csv',\n",
    "                   'features_3q18.csv'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in initial file to start surp_data df\n",
    "\n",
    "surp_data = pd.read_csv('data/surp_1q14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>co_name</th>\n",
       "      <th>unique_earnings_code</th>\n",
       "      <th>factset_sector_num</th>\n",
       "      <th>factset_ind_num</th>\n",
       "      <th>calendar_qtr</th>\n",
       "      <th>fiscal_qtr</th>\n",
       "      <th>adtv_prev_month</th>\n",
       "      <th>report_date</th>\n",
       "      <th>rtn_t+3</th>\n",
       "      <th>...</th>\n",
       "      <th>rtn_t+3_check</th>\n",
       "      <th>mkt_t+3_rtn</th>\n",
       "      <th>rel_t+3_rtn</th>\n",
       "      <th>num_ests_qtr_end</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-7_high_est</th>\n",
       "      <th>t-7_low_est</th>\n",
       "      <th>est_spread</th>\n",
       "      <th>spread_adj_surp</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAMP</td>\n",
       "      <td>LiveRamp Holdings, Inc.</td>\n",
       "      <td>RAMP.1Q14</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>1Q14</td>\n",
       "      <td>2013/4F</td>\n",
       "      <td>14.4</td>\n",
       "      <td>05/15/2014</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-21.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5/8/2014</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-58.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMBC</td>\n",
       "      <td>Ambac Financial Group, Inc.</td>\n",
       "      <td>AMBC.1Q14</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>4875.0</td>\n",
       "      <td>1Q14</td>\n",
       "      <td>2014/1F</td>\n",
       "      <td>17.6</td>\n",
       "      <td>05/13/2014</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5/6/2014</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.12</td>\n",
       "      <td>23.333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCO</td>\n",
       "      <td>Taubman Centers, Inc.</td>\n",
       "      <td>TCO.1Q14</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>4890.0</td>\n",
       "      <td>1Q14</td>\n",
       "      <td>2014/1F</td>\n",
       "      <td>37.3</td>\n",
       "      <td>04/25/2014</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4/18/2014</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.27</td>\n",
       "      <td>19.904</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WRI</td>\n",
       "      <td>Weingarten Realty Investors</td>\n",
       "      <td>WRI.1Q14</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>4890.0</td>\n",
       "      <td>1Q14</td>\n",
       "      <td>2014/1F</td>\n",
       "      <td>25.3</td>\n",
       "      <td>04/25/2014</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4/18/2014</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>19.380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LF</td>\n",
       "      <td>LeapFrog Enterprises, Inc. Class A</td>\n",
       "      <td>LF.1Q14</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>1Q14</td>\n",
       "      <td>2013/4F</td>\n",
       "      <td>6.4</td>\n",
       "      <td>02/13/2014</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2/6/2014</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>12.833</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker_symbol                             co_name unique_earnings_code  \\\n",
       "0          RAMP             LiveRamp Holdings, Inc.            RAMP.1Q14   \n",
       "1          AMBC         Ambac Financial Group, Inc.            AMBC.1Q14   \n",
       "2           TCO               Taubman Centers, Inc.             TCO.1Q14   \n",
       "3           WRI         Weingarten Realty Investors             WRI.1Q14   \n",
       "4            LF  LeapFrog Enterprises, Inc. Class A              LF.1Q14   \n",
       "\n",
       "   factset_sector_num  factset_ind_num calendar_qtr fiscal_qtr  \\\n",
       "0              3300.0           3305.0         1Q14    2013/4F   \n",
       "1              4800.0           4875.0         1Q14    2014/1F   \n",
       "2              4800.0           4890.0         1Q14    2014/1F   \n",
       "3              4800.0           4890.0         1Q14    2014/1F   \n",
       "4              1400.0           1435.0         1Q14    2013/4F   \n",
       "\n",
       "  adtv_prev_month report_date  rtn_t+3  ... rtn_t+3_check mkt_t+3_rtn  \\\n",
       "0            14.4  05/15/2014    -22.0  ...         -22.0        -0.8   \n",
       "1            17.6  05/13/2014     -1.3  ...          -1.3        -1.1   \n",
       "2            37.3  04/25/2014     -0.2  ...          -0.2         0.2   \n",
       "3            25.3  04/25/2014      0.3  ...           0.3         0.2   \n",
       "4             6.4  02/13/2014     -3.7  ...          -6.3         1.3   \n",
       "\n",
       "  rel_t+3_rtn  num_ests_qtr_end        t-7 t-7_high_est t-7_low_est  \\\n",
       "0       -21.2               4.0   5/8/2014         0.20        0.19   \n",
       "1        -0.2               2.0   5/6/2014         1.01        0.89   \n",
       "2        -0.3               7.0  4/18/2014         0.50        0.23   \n",
       "3         0.1               2.0  4/18/2014         0.15        0.13   \n",
       "4        -7.5               1.0   2/6/2014         0.17        0.11   \n",
       "\n",
       "   est_spread  spread_adj_surp Unnamed: 26  \n",
       "0        0.01          -58.000         NaN  \n",
       "1        0.12           23.333         NaN  \n",
       "2        0.27           19.904         NaN  \n",
       "3        0.02           19.380         NaN  \n",
       "4        0.06           12.833         NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect surp_data\n",
    "\n",
    "surp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"new_columns =[]\\n\\nfor col in columns:\\n    if col[-1] == 'F':\\n        new_columns.append(col)\\n        \\nnew_columns.insert(0, 'unique_earnings_code')\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"new_columns =[]\n",
    "\n",
    "for col in columns:\n",
    "    if col[-1] == 'F':\n",
    "        new_columns.append(col)\n",
    "        \n",
    "new_columns.insert(0, 'unique_earnings_code')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to facilitate extracting columns with features, tagged with a trailing F\n",
    "\n",
    "def create_feature_df_index(df):\n",
    "    \"\"\"Creates a new Index for extracting columns coded with a trailing 'F'from a dataframe\"\"\"\n",
    "    \n",
    "    old_columns = list(df.columns)\n",
    "    new_columns = []\n",
    "    \n",
    "    for col in old_columns:\n",
    "        if col[-1] == 'F':\n",
    "            new_columns.append(col)\n",
    "        \n",
    "    new_columns.insert(0, 'unique_earnings_code')\n",
    "    ind_obj = pd.Index(new_columns)\n",
    "    \n",
    "    return ind_obj\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do a clean merge of the surprise and feature dataframes\n",
    "\n",
    "def clean_feature_bind(surp_df, feature_df, retained_columns):\n",
    "    \"\"\"Creates a tidied up df from a surp_df and feature_df, based on an Index object of cols to retain.\"\"\"\n",
    "    \n",
    "    bound_df = pd.merge(surp_df, feature_df[retained_columns], on='unique_earnings_code')\n",
    "    \n",
    "    return bound_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidyfy_surp_df(df):\n",
    "    \"\"\"Clean up Surp dataframes prior to join\"\"\"\n",
    "    new_cols = ['ticker_symbol',\n",
    "                 'co_name',\n",
    "                 'unique_earnings_code',\n",
    "                 'factset_sector_num',\n",
    "                 'factset_ind_num',\n",
    "                 'calendar_qtr',\n",
    "                 'fiscal_qtr',\n",
    "                 'adtv_prev_month',\n",
    "                 'report_date',\n",
    "                 'eps_est',\n",
    "                 'eps_actual',\n",
    "                 'surp_amt',\n",
    "                 'rtn_t+3',\n",
    "                 'mkt_t+3_rtn',\n",
    "                 'rel_t+3_rtn',\n",
    "                 'num_ests_qtr_end',\n",
    "                 't-7_high_est',\n",
    "                 't-7_low_est',\n",
    "                 'est_spread',\n",
    "                 'spread_adj_surp']\n",
    "    \n",
    "    tidy_df = df[new_cols]\n",
    "    tidy_df = tidy_df.drop_duplicates()\n",
    "    \n",
    "    return tidy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_merged_frames(surp_lst, features_lst):\n",
    "    \"\"\"Create combined dataframes from two lists of dataframe names: surp & features\"\"\"\n",
    "    \n",
    "    combined_df_lst = []\n",
    "    \n",
    "    for s_df, f_df in zip(surp_lst, features_lst):\n",
    "        #create quarter tag\n",
    "        tag = s_df[-8:]\n",
    "\n",
    "        # read surp df\n",
    "        surp_df = pd.read_csv('data/'+s_df)\n",
    "        tidy_surp_df = tidyfy_surp_df(surp_df)\n",
    "        # read feature df\n",
    "        feature_df = pd.read_csv('data/'+f_df)\n",
    "\n",
    "        # create list of columns to retain\n",
    "        retained_cols = create_feature_df_index(feature_df)\n",
    "\n",
    "        # create combined df\n",
    "        combined_df = clean_feature_bind(tidy_surp_df, feature_df, retained_cols)\n",
    "        combined_df.reset_index()\n",
    "\n",
    "        # write combined_df to a csv file and store in data folder\n",
    "        combined_df.to_csv('data/combined_'+tag, index=False)\n",
    "        \n",
    "        # record df written to a list\n",
    "        combined_df_lst.append('combined_'+tag)\n",
    "    \n",
    "    return combined_df_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_frames = write_merged_frames(surp_files, features_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combined_1q14.csv',\n",
       " 'combined_2q14.csv',\n",
       " 'combined_3q14.csv',\n",
       " 'combined_4q14.csv',\n",
       " 'combined_1q15.csv',\n",
       " 'combined_2q15.csv',\n",
       " 'combined_3q15.csv',\n",
       " 'combined_4q15.csv',\n",
       " 'combined_1q16.csv',\n",
       " 'combined_2q16.csv',\n",
       " 'combined_3q16.csv',\n",
       " 'combined_4q16.csv',\n",
       " 'combined_1q17.csv',\n",
       " 'combined_2q17.csv',\n",
       " 'combined_3q17.csv',\n",
       " 'combined_4q17.csv',\n",
       " 'combined_1q18.csv',\n",
       " 'combined_2q18.csv',\n",
       " 'combined_3q18.csv']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_frames(sequence):\n",
    "    sequence = sequence.copy()\n",
    "\n",
    "    combined_full = pd.concat([pd.read_csv(f'data/{file}', low_memory=False) for file in sequence])\n",
    "    combined_full = combined_full.drop_duplicates()\n",
    "    \n",
    "    combined_full.to_csv('data/combined_full_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stack_frames(combined_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Ticker List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of tickers\n",
    "\n",
    "tickers = surp_data['ticker_symbol']\n",
    "tickers = list(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check length of ticker list\n",
    "\n",
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of unique tickers by passing it through a set\n",
    "\n",
    "tickers = list(set(tickers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tickers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_tickers_to_file(ticker_list, filename):\n",
    "    \n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for tickers in ticker_list:\n",
    "            outfile.write(tickers)\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_write_tickers_to_file(tickers, 'tickers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quandl API Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = 'jUKZLy5xi7gGFf3sSF-r'\n",
    "exr_Hv10 = quandl.get('VOL/EXR', start_date='2013-01-02', end_date='2019-04-01', column_index='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"vol_data/VOL_20190401.csv\") as myfile:\n",
    "#    head = [next(myfile).split(',') for x in range(1)]\n",
    "#print(head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"with open(\"vol_data/VOL_20190401.csv\") as myfile:\n",
    "    stock_data = []\n",
    "    started = False\n",
    "    for idx, line in enumerate(myfile):\n",
    "        fields = line.strip().split(',')\n",
    "        if fields[0] == 'APTV' and fields[1] > '2018-02-09':\n",
    "            started = True\n",
    "        if not started:\n",
    "            continue\n",
    "                \n",
    "        if fields[0] in tickers and fields[1] > '2018-01-01' and fields[1] < '2018-12-31':\n",
    "            stock_data.append(fields)\"\"\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_data_to_file(data, filename):\n",
    "    with open(filename, \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_write_data_to_file(stock_data, \"data/stock_vol_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
